{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lineare regression we have one independent variable and one dependent variable. In multiple regression we have multiple independent variable and one depenedent variable. the depenedent variable we may call that as a predictor or response variable. \n",
    "\n",
    "If you add more indepent variables to predict the dependent variable, that not reduce the error perecentage of prediction, it's increase the error percentage. this is called over fitting.\n",
    "\n",
    "Not only IV has a good corelation with DV, The IVs among tem has good corelation. if you add more IVs that may leads to the strong relation among the IVs. This is called Multi-co-linearity. this also leads to increase the error percetage of prediction.\n",
    "\n",
    "The ideal scenario is the IVs has corelated DV but not among them.\n",
    "\n",
    "before going to model calculation need to do some propwork, i.e select the IV which are highly corelated with DV. Can do using scatter plots and corelation calcualtion. And also need to check for multicolinearity, find the corelation among the IV.\n",
    "\n",
    "do the linear regression with the pair of IV/DV.\n",
    "\n",
    "Finding the redudant IVs which have strong relationship among them and use one IV to reduce the multicolinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
